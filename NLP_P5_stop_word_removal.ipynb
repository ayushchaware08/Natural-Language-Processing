{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEupIwwq/nnhYnfc+orLSb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name** Ayush Chaware\n",
        "\n",
        "**Roll no** 22"
      ],
      "metadata": {
        "id": "pEa-w4sZFn5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Without Inbuild Package"
      ],
      "metadata": {
        "id": "XMnncgLh3ZpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkuYCXmt82d2",
        "outputId": "082104b6-76f5-46ae-af6a-8a461d97db2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-WnH4dNzBYX"
      },
      "outputs": [],
      "source": [
        "corpus = \"Stopwords are frequently occurring words in a language that are frequently omitted from natural language processing (NLP) tasks due to their  low significance for deciphering textual meaning. The particular list of stopwords can change based on the language being studied and the context.\"\n",
        "stopword = [\"are\", \"in\", \"a\",\"that\",\"are\",\"from\",\"due\",\"to\",\"their\",\"for\", \"the\" , \"of\" , \"can\" , \"based\" , \"on\" , \"being\", \"and\" , \"(\", \")\", \".\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_token = nltk.word_tokenize(corpus.lower())"
      ],
      "metadata": {
        "id": "pnib_nlq9GCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus_token[:]:\n",
        "  if i in stopword:\n",
        "    corpus_token.remove(i)"
      ],
      "metadata": {
        "id": "jMu2IvXv9H-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus_token)"
      ],
      "metadata": {
        "id": "EXmFNQ0K99p2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1417e29e-45d0-4f68-8410-803fd0138079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stopwords', 'frequently', 'occurring', 'words', 'language', 'frequently', 'omitted', 'natural', 'language', 'processing', 'nlp', 'tasks', 'low', 'significance', 'deciphering', 'textual', 'meaning', 'particular', 'list', 'stopwords', 'change', 'language', 'studied', 'context']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Stop Word Removal using NLTK"
      ],
      "metadata": {
        "id": "my9EZvMuBhbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVWHWCwyAvST",
        "outputId": "f45771cb-4064-419f-ae68-82b0d8d5f843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "IU5WPmb-B5K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopword = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "rPkTAJzWB5Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"Stopwords are frequently occurring words in a language that are frequently omitted from natural language processing (NLP) tasks due to their  low significance for deciphering textual meaning. The particular list of stopwords can change based on the language being studied and the context.\"\n",
        "stopword = [\"are\", \"in\", \"a\",\"that\",\"are\",\"from\",\"due\",\"to\",\"their\",\"for\", \"the\" , \"of\" , \"can\" , \"based\" , \"on\" , \"being\", \"and\" , \"(\", \")\", \".\"]\n",
        "corpus_token = nltk.word_tokenize(corpus.lower())"
      ],
      "metadata": {
        "id": "2MUWUuVXB4_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence = [w for w in corpus_token if not w.lower() in stopword]\n",
        "filtered_sentence = []\n",
        "for w in corpus_token:\n",
        "    if w not in stopword:\n",
        "        filtered_sentence.append(w)\n",
        "# print(corpus_token)\n",
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFi11jgiC4MH",
        "outputId": "c0ce595c-9fbf-430a-8a87-c7b65ebae491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stopwords', 'frequently', 'occurring', 'words', 'language', 'frequently', 'omitted', 'natural', 'language', 'processing', 'nlp', 'tasks', 'low', 'significance', 'deciphering', 'textual', 'meaning', 'particular', 'list', 'stopwords', 'change', 'language', 'studied', 'context']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Stop Word Removal using Spacy"
      ],
      "metadata": {
        "id": "pho3zkIZAp5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "7RdvvdqYBfFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(corpus)"
      ],
      "metadata": {
        "id": "eX_R3aHjEMDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_words = [token.text for token in doc if not token.is_stop]\n",
        "clean_text = ' '.join(filtered_words)\n",
        "print(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmoGFjx9E13W",
        "outputId": "acc9daf5-6b62-49fb-b36b-cb3ace43a445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords frequently occurring words language frequently omitted natural language processing ( NLP ) tasks   low significance deciphering textual meaning . particular list stopwords change based language studied context .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Stop word Removal using Genism"
      ],
      "metadata": {
        "id": "sXBgDOcFBoII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "filtered_text = remove_stopwords(corpus)\n",
        "\n",
        "print(filtered_text)"
      ],
      "metadata": {
        "id": "FgRClYtABvm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2fb6f1-3330-4089-be61-377321cc6bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords frequently occurring words language frequently omitted natural language processing (NLP) tasks low significance deciphering textual meaning. The particular list stopwords change based language studied context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XHVNStZMIIGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WP9O52CPIoUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}